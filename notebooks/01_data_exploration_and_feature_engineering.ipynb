{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd19b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please download the dataset from Kaggle and update the file paths\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     beneficiary_df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mwebprogproject\u001b[39m\u001b[38;5;130;01m\\f\u001b[39;00m\u001b[33mraud_detection_project\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mTrain_Beneficiarydata.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m     inpatient_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mwebprogproject\u001b[39m\u001b[38;5;130;01m\\f\u001b[39;00m\u001b[33mraud_detection_project\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mTrain_Inpatientdata.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPlease download the dataset from Kaggle and update the file paths\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Create sample data structures for code demonstration\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m beneficiary_df = \u001b[43mpd\u001b[49m.DataFrame()\n\u001b[32m     22\u001b[39m inpatient_df = pd.DataFrame()\n\u001b[32m     23\u001b[39m outpatient_df = pd.DataFrame()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    beneficiary_df = pd.read_csv('/content/Train_Beneficiarydata.csv')\n",
    "    inpatient_df = pd.read_csv('/content/Train_Inpatientdata.csv')\n",
    "    outpatient_df = pd.read_csv('/content/Train_Outpatientdata.csv')\n",
    "    labels_df = pd.read_csv('/content/Train_labels.csv') \n",
    "except:\n",
    "    # If files aren't available, we'll create sample code structure\n",
    "    print(\"Please download the dataset from Kaggle and update the file paths\")\n",
    "    # Create sample data structures for code demonstration\n",
    "    beneficiary_df = pd.DataFrame()\n",
    "    inpatient_df = pd.DataFrame()\n",
    "    outpatient_df = pd.DataFrame()\n",
    "    labels_df = pd.DataFrame()\n",
    "\n",
    "# %%\n",
    "# Basic data exploration\n",
    "def explore_dataset(df, name):\n",
    "    print(f\"\\n=== {name} Dataset ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    if not df.empty:\n",
    "        print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "        print(f\"Data types:\\n{df.dtypes}\")\n",
    "\n",
    "explore_dataset(beneficiary_df, \"Beneficiary\")\n",
    "explore_dataset(inpatient_df, \"Inpatient\")\n",
    "explore_dataset(outpatient_df, \"Outpatient\")\n",
    "explore_dataset(labels_df, \"Labels\")\n",
    "\n",
    "# %%\n",
    "# Check target distribution\n",
    "if not labels_df.empty:\n",
    "    print(\"\\n=== Target Distribution ===\")\n",
    "    print(labels_df['PotentialFraud'].value_counts())\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    labels_df['PotentialFraud'].value_counts().plot(kind='bar')\n",
    "    plt.title('Target Class Distribution')\n",
    "    plt.xlabel('Potential Fraud')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ## 1.2 Data Preprocessing and Cleaning\n",
    "\n",
    "# %%\n",
    "def preprocess_beneficiary_data(df):\n",
    "    \"\"\"Preprocess beneficiary demographic data\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Handle missing values\n",
    "    df = df.fillna({'DOD': '1900-01-01'})  # Fill missing death dates\n",
    "\n",
    "    # Convert dates\n",
    "    date_cols = ['DOB', 'DOD', 'ClaimStartDate', 'ClaimEndDate']\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Calculate age\n",
    "    if 'DOB' in df.columns:\n",
    "        reference_date = pd.to_datetime('2020-12-31')  # Assuming current date\n",
    "        df['Age'] = (reference_date - df['DOB']).dt.days // 365\n",
    "\n",
    "    # Create flags for chronic conditions\n",
    "    chronic_conditions = ['ChronicCond_Heartfailure', 'ChronicCond_Alzheimer',\n",
    "                         'ChronicCond_Cancer', 'ChronicCond_KidneyDisease',\n",
    "                         'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression',\n",
    "                         'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart',\n",
    "                         'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n",
    "                         'ChronicCond_stroke']\n",
    "    for condition in chronic_conditions:\n",
    "        if condition in df.columns:\n",
    "            df[f'{condition}_Flag'] = df[condition].fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# %%\n",
    "def preprocess_claims_data(df, claim_type):\n",
    "    \"\"\"Preprocess inpatient/outpatient claims data\"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    # Convert dates\n",
    "    date_cols = ['ClaimStartDate', 'ClaimEndDate', 'AdmissionDate', 'DischargeDate']\n",
    "    for col in date_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Calculate claim duration\n",
    "    if 'ClaimStartDate' in df.columns and 'ClaimEndDate' in df.columns:\n",
    "        df['ClaimDuration'] = (df['ClaimEndDate'] - df['ClaimStartDate']).dt.days\n",
    "\n",
    "    # Create amount-related features\n",
    "    amount_cols = ['DeductibleAmtPaid', 'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
    "                   'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt']\n",
    "    for col in amount_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ## 1.3 Feature Engineering\n",
    "\n",
    "# %%\n",
    "def create_provider_level_features(beneficiary_df, inpatient_df, outpatient_df, labels_df):\n",
    "    \"\"\"Aggregate claim-level data to provider-level features\"\"\"\n",
    "    provider_features = []\n",
    "\n",
    "    if not labels_df.empty:\n",
    "        providers = labels_df['Provider'].unique()\n",
    "    else:\n",
    "        # Sample providers for demonstration\n",
    "        providers = ['PRV00001', 'PRV00002']\n",
    "\n",
    "    for provider in providers:\n",
    "        provider_data = {}\n",
    "\n",
    "        # Provider ID\n",
    "        provider_data['Provider'] = provider\n",
    "\n",
    "        # Get provider's claims\n",
    "        if not inpatient_df.empty:\n",
    "            provider_inpatient = inpatient_df[inpatient_df['Provider'] == provider]\n",
    "        else:\n",
    "            provider_inpatient = pd.DataFrame()\n",
    "\n",
    "        if not outpatient_df.empty:\n",
    "            provider_outpatient = outpatient_df[outpatient_df['Provider'] == provider]\n",
    "        else:\n",
    "            provider_outpatient = pd.DataFrame()\n",
    "\n",
    "        # Basic counts\n",
    "        provider_data['Total_Inpatient_Claims'] = len(provider_inpatient)\n",
    "        provider_data['Total_Outpatient_Claims'] = len(provider_outpatient)\n",
    "        provider_data['Total_Claims'] = provider_data['Total_Inpatient_Claims'] + provider_data['Total_Outpatient_Claims']\n",
    "\n",
    "        # Amount features\n",
    "        if not provider_inpatient.empty and 'InscClaimAmtReimbursed' in provider_inpatient.columns:\n",
    "            provider_data['Avg_Inpatient_Claim_Amount'] = provider_inpatient['InscClaimAmtReimbursed'].mean()\n",
    "            provider_data['Total_Inpatient_Amount'] = provider_inpatient['InscClaimAmtReimbursed'].sum()\n",
    "        else:\n",
    "            provider_data['Avg_Inpatient_Claim_Amount'] = 0\n",
    "            provider_data['Total_Inpatient_Amount'] = 0\n",
    "\n",
    "        if not provider_outpatient.empty and 'InscClaimAmtReimbursed' in provider_outpatient.columns:\n",
    "            provider_data['Avg_Outpatient_Claim_Amount'] = provider_outpatient['InscClaimAmtReimbursed'].mean()\n",
    "            provider_data['Total_Outpatient_Amount'] = provider_outpatient['InscClaimAmtReimbursed'].sum()\n",
    "        else:\n",
    "            provider_data['Avg_Outpatient_Claim_Amount'] = 0\n",
    "            provider_data['Total_Outpatient_Amount'] = 0\n",
    "\n",
    "        provider_data['Total_Amount_Reimbursed'] = provider_data['Total_Inpatient_Amount'] + provider_data['Total_Outpatient_Amount']\n",
    "\n",
    "        # Ratio features\n",
    "        if provider_data['Total_Claims'] > 0:\n",
    "            provider_data['Inpatient_Claim_Ratio'] = provider_data['Total_Inpatient_Claims'] / provider_data['Total_Claims']\n",
    "        else:\n",
    "            provider_data['Inpatient_Claim_Ratio'] = 0\n",
    "\n",
    "        # Physician count features\n",
    "        if not provider_inpatient.empty:\n",
    "            provider_data['Unique_AttendingPhysicians_Inpatient'] = provider_inpatient['AttendingPhysician'].nunique()\n",
    "        else:\n",
    "            provider_data['Unique_AttendingPhysicians_Inpatient'] = 0\n",
    "\n",
    "        if not provider_outpatient.empty:\n",
    "            provider_data['Unique_AttendingPhysicians_Outpatient'] = provider_outpatient['AttendingPhysician'].nunique()\n",
    "        else:\n",
    "            provider_data['Unique_AttendingPhysicians_Outpatient'] = 0\n",
    "\n",
    "        provider_features.append(provider_data)\n",
    "\n",
    "    return pd.DataFrame(provider_features)\n",
    "\n",
    "# %%\n",
    "# Create feature dataset\n",
    "features_df = create_provider_level_features(beneficiary_df, inpatient_df, outpatient_df, labels_df)\n",
    "\n",
    "# Merge with labels\n",
    "if not labels_df.empty and not features_df.empty:\n",
    "    final_df = pd.merge(features_df, labels_df, on='Provider', how='left')\n",
    "else:\n",
    "    final_df = features_df\n",
    "\n",
    "print(\"Final feature dataset shape:\", final_df.shape)\n",
    "print(\"Final features:\", list(final_df.columns))\n",
    "\n",
    "\n",
    "# ## 1.4 Exploratory Data Analysis\n",
    "\n",
    "# %%\n",
    "def perform_eda(df):\n",
    "    \"\"\"Perform exploratory data analysis\"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    # Numerical features distribution\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numerical_cols) > 0:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.ravel()\n",
    "        for i, col in enumerate(numerical_cols[:6]):\n",
    "            df[col].hist(bins=30, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Correlation heatmap\n",
    "    if len(numerical_cols) > 1:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        correlation_matrix = df[numerical_cols].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Feature Correlation Heatmap')\n",
    "        plt.show()\n",
    "\n",
    "    # Target vs features analysis\n",
    "    if 'PotentialFraud' in df.columns:\n",
    "        fraud_df = df[df['PotentialFraud'] == 'Yes']\n",
    "        non_fraud_df = df[df['PotentialFraud'] == 'No']\n",
    "\n",
    "        # Compare means\n",
    "        comparison_df = pd.DataFrame({\n",
    "            'Fraud_Mean': fraud_df[numerical_cols].mean(),\n",
    "            'Non_Fraud_Mean': non_fraud_df[numerical_cols].mean()\n",
    "        })\n",
    "        comparison_df['Difference'] = comparison_df['Fraud_Mean'] - comparison_df['Non_Fraud_Mean']\n",
    "        print(\"\\nFeature Comparison (Fraud vs Non-Fraud):\")\n",
    "        print(comparison_df)\n",
    "\n",
    "perform_eda(final_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
